{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optuna + Keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/optuna_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JTuTSjwnmc7"
      },
      "source": [
        "# Global optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfiJx7xDpbwS"
      },
      "source": [
        "In this task you will use [optuna](https://optuna.org/) package for \n",
        "hyperparameter optimization in credit card Fraud detection dataset. Examples can be find [here](https://optuna.org/#code_examples) or [here](https://www.kaggle.com/dixhom/bayesian-optimization-with-optuna-stacking/)\n",
        "\n",
        "This [example](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/structured_data/ipynb/imbalanced_classification.ipynb#scrollTo=yxK_u7msJeI6) looks at the [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/) dataset to demonstrate how to train a classification model on data with highly imbalanced classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBznFFn0sZH6",
        "outputId": "f96c2c9d-f478-4a03-fbbe-1d0e88b3312a"
      },
      "source": [
        "!pip install optuna\n",
        "!pip install keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 35.8 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 38.5 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 34.8 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=9d8dab9354211f6e2187f13aaa0796073d5cf636a6448d347f5b196db68fef88\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0hLaBcGNM69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b0026c-6282-45c1-cf07-2187e4a27214"
      },
      "source": [
        "# Getting dataset with credit card data\n",
        "!wget -O creditcard.csv.zip \"https://github.com/MerkulovDaniil/optim/raw/master/assets/Notebooks/creditcard.csv.zip\"\n",
        "!unzip creditcard.csv.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-17 20:02:38--  https://github.com/MerkulovDaniil/optim/raw/master/assets/Notebooks/creditcard.csv.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MerkulovDaniil/optim/master/assets/Notebooks/creditcard.csv.zip [following]\n",
            "--2022-02-17 20:02:38--  https://raw.githubusercontent.com/MerkulovDaniil/optim/master/assets/Notebooks/creditcard.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69155672 (66M) [application/zip]\n",
            "Saving to: ‘creditcard.csv.zip’\n",
            "\n",
            "creditcard.csv.zip  100%[===================>]  65.95M   161MB/s    in 0.4s    \n",
            "\n",
            "2022-02-17 20:02:39 (161 MB/s) - ‘creditcard.csv.zip’ saved [69155672/69155672]\n",
            "\n",
            "Archive:  creditcard.csv.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJSyOUAiNvPB"
      },
      "source": [
        "## First, vectorize the CSV data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAMMadr9sZaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39432cb2-1e75-4e50-cf20-2b3ccbf44531"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
        "\n",
        "fname = \"creditcard.csv\"\n",
        "\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        fields = line.strip().split(\",\")\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
        "\n",
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uBKafeqJeI7"
      },
      "source": [
        "## Prepare a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqYMj_XGJeI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dfc4662-4384-4a80-9d2c-c1a3c47a0bdf"
      },
      "source": [
        "num_val_samples = int(len(features) * 0.2)\n",
        "train_features = features[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_features = features[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "print(\"Number of training samples:\", len(train_features))\n",
        "print(\"Number of validation samples:\", len(val_features))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 227846\n",
            "Number of validation samples: 56961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIngOB-LJeI8"
      },
      "source": [
        "## Analyze class imbalance in the targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQZIqbUiJeI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ca8110-25bd-4a35-8cc8-1898a39d75b9"
      },
      "source": [
        "counts = np.bincount(train_targets[:, 0])\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive samples in training data: 417 (0.18% of total)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCMrVl_0JeI9"
      },
      "source": [
        "## Normalize the data using training set statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UejackMJeI9"
      },
      "source": [
        "mean = np.mean(train_features, axis=0)\n",
        "train_features -= mean\n",
        "val_features -= mean\n",
        "std = np.std(train_features, axis=0)\n",
        "train_features /= std\n",
        "val_features /= std\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "807U58T2JeI-"
      },
      "source": [
        "## Build a binary classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdFUgYwbJeI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42dc832d-6e9f-433c-fbed-538638ecf888"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(\n",
        "            256, activation=\"relu\", input_shape=(train_features.shape[-1],)\n",
        "        ),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               7936      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139,777\n",
            "Trainable params: 139,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM-QO7OpJeI-"
      },
      "source": [
        "## Train the model with `class_weight` argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiRZiESuJeI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f690650-07f7-49f4-f4ea-3b94c7c2ed4e"
      },
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    class_weight=class_weight,\n",
        ")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 7s - loss: 2.4558e-06 - fn: 47.0000 - fp: 31589.0000 - tn: 195840.0000 - tp: 370.0000 - precision: 0.0116 - recall: 0.8873 - val_loss: 0.1757 - val_fn: 7.0000 - val_fp: 2326.0000 - val_tn: 54560.0000 - val_tp: 68.0000 - val_precision: 0.0284 - val_recall: 0.9067 - 7s/epoch - 61ms/step\n",
            "Epoch 2/30\n",
            "112/112 - 1s - loss: 1.4774e-06 - fn: 35.0000 - fp: 8201.0000 - tn: 219228.0000 - tp: 382.0000 - precision: 0.0445 - recall: 0.9161 - val_loss: 0.0486 - val_fn: 10.0000 - val_fp: 303.0000 - val_tn: 56583.0000 - val_tp: 65.0000 - val_precision: 0.1766 - val_recall: 0.8667 - 1s/epoch - 13ms/step\n",
            "Epoch 3/30\n",
            "112/112 - 1s - loss: 1.4111e-06 - fn: 29.0000 - fp: 7187.0000 - tn: 220242.0000 - tp: 388.0000 - precision: 0.0512 - recall: 0.9305 - val_loss: 0.0389 - val_fn: 11.0000 - val_fp: 247.0000 - val_tn: 56639.0000 - val_tp: 64.0000 - val_precision: 0.2058 - val_recall: 0.8533 - 1s/epoch - 12ms/step\n",
            "Epoch 4/30\n",
            "112/112 - 1s - loss: 1.0237e-06 - fn: 23.0000 - fp: 6829.0000 - tn: 220600.0000 - tp: 394.0000 - precision: 0.0545 - recall: 0.9448 - val_loss: 0.0773 - val_fn: 7.0000 - val_fp: 1252.0000 - val_tn: 55634.0000 - val_tp: 68.0000 - val_precision: 0.0515 - val_recall: 0.9067 - 1s/epoch - 11ms/step\n",
            "Epoch 5/30\n",
            "112/112 - 1s - loss: 8.8305e-07 - fn: 23.0000 - fp: 6474.0000 - tn: 220955.0000 - tp: 394.0000 - precision: 0.0574 - recall: 0.9448 - val_loss: 0.1382 - val_fn: 6.0000 - val_fp: 3600.0000 - val_tn: 53286.0000 - val_tp: 69.0000 - val_precision: 0.0188 - val_recall: 0.9200 - 1s/epoch - 11ms/step\n",
            "Epoch 6/30\n",
            "112/112 - 1s - loss: 6.9658e-07 - fn: 13.0000 - fp: 5564.0000 - tn: 221865.0000 - tp: 404.0000 - precision: 0.0677 - recall: 0.9688 - val_loss: 0.0885 - val_fn: 7.0000 - val_fp: 1461.0000 - val_tn: 55425.0000 - val_tp: 68.0000 - val_precision: 0.0445 - val_recall: 0.9067 - 1s/epoch - 13ms/step\n",
            "Epoch 7/30\n",
            "112/112 - 1s - loss: 2.7194e-06 - fn: 35.0000 - fp: 10397.0000 - tn: 217032.0000 - tp: 382.0000 - precision: 0.0354 - recall: 0.9161 - val_loss: 0.0582 - val_fn: 10.0000 - val_fp: 623.0000 - val_tn: 56263.0000 - val_tp: 65.0000 - val_precision: 0.0945 - val_recall: 0.8667 - 1s/epoch - 11ms/step\n",
            "Epoch 8/30\n",
            "112/112 - 1s - loss: 3.7370e-06 - fn: 28.0000 - fp: 8603.0000 - tn: 218826.0000 - tp: 389.0000 - precision: 0.0433 - recall: 0.9329 - val_loss: 0.0711 - val_fn: 12.0000 - val_fp: 377.0000 - val_tn: 56509.0000 - val_tp: 63.0000 - val_precision: 0.1432 - val_recall: 0.8400 - 1s/epoch - 11ms/step\n",
            "Epoch 9/30\n",
            "112/112 - 1s - loss: 3.5024e-06 - fn: 29.0000 - fp: 7024.0000 - tn: 220405.0000 - tp: 388.0000 - precision: 0.0523 - recall: 0.9305 - val_loss: 0.0914 - val_fn: 12.0000 - val_fp: 227.0000 - val_tn: 56659.0000 - val_tp: 63.0000 - val_precision: 0.2172 - val_recall: 0.8400 - 1s/epoch - 11ms/step\n",
            "Epoch 10/30\n",
            "112/112 - 1s - loss: 1.2951e-06 - fn: 25.0000 - fp: 4924.0000 - tn: 222505.0000 - tp: 392.0000 - precision: 0.0737 - recall: 0.9400 - val_loss: 0.0492 - val_fn: 8.0000 - val_fp: 590.0000 - val_tn: 56296.0000 - val_tp: 67.0000 - val_precision: 0.1020 - val_recall: 0.8933 - 1s/epoch - 12ms/step\n",
            "Epoch 11/30\n",
            "112/112 - 1s - loss: 8.1486e-07 - fn: 14.0000 - fp: 5440.0000 - tn: 221989.0000 - tp: 403.0000 - precision: 0.0690 - recall: 0.9664 - val_loss: 0.0712 - val_fn: 6.0000 - val_fp: 1356.0000 - val_tn: 55530.0000 - val_tp: 69.0000 - val_precision: 0.0484 - val_recall: 0.9200 - 1s/epoch - 11ms/step\n",
            "Epoch 12/30\n",
            "112/112 - 1s - loss: 5.9930e-07 - fn: 11.0000 - fp: 4886.0000 - tn: 222543.0000 - tp: 406.0000 - precision: 0.0767 - recall: 0.9736 - val_loss: 0.0258 - val_fn: 11.0000 - val_fp: 428.0000 - val_tn: 56458.0000 - val_tp: 64.0000 - val_precision: 0.1301 - val_recall: 0.8533 - 1s/epoch - 11ms/step\n",
            "Epoch 13/30\n",
            "112/112 - 1s - loss: 6.9014e-07 - fn: 10.0000 - fp: 4278.0000 - tn: 223151.0000 - tp: 407.0000 - precision: 0.0869 - recall: 0.9760 - val_loss: 0.1187 - val_fn: 8.0000 - val_fp: 1519.0000 - val_tn: 55367.0000 - val_tp: 67.0000 - val_precision: 0.0422 - val_recall: 0.8933 - 1s/epoch - 11ms/step\n",
            "Epoch 14/30\n",
            "112/112 - 1s - loss: 9.1954e-07 - fn: 17.0000 - fp: 9544.0000 - tn: 217885.0000 - tp: 400.0000 - precision: 0.0402 - recall: 0.9592 - val_loss: 0.0605 - val_fn: 8.0000 - val_fp: 1383.0000 - val_tn: 55503.0000 - val_tp: 67.0000 - val_precision: 0.0462 - val_recall: 0.8933 - 1s/epoch - 11ms/step\n",
            "Epoch 15/30\n",
            "112/112 - 1s - loss: 6.5939e-07 - fn: 10.0000 - fp: 6130.0000 - tn: 221299.0000 - tp: 407.0000 - precision: 0.0623 - recall: 0.9760 - val_loss: 0.1683 - val_fn: 6.0000 - val_fp: 2318.0000 - val_tn: 54568.0000 - val_tp: 69.0000 - val_precision: 0.0289 - val_recall: 0.9200 - 1s/epoch - 11ms/step\n",
            "Epoch 16/30\n",
            "112/112 - 1s - loss: 7.0744e-07 - fn: 12.0000 - fp: 5341.0000 - tn: 222088.0000 - tp: 405.0000 - precision: 0.0705 - recall: 0.9712 - val_loss: 0.0890 - val_fn: 5.0000 - val_fp: 1883.0000 - val_tn: 55003.0000 - val_tp: 70.0000 - val_precision: 0.0358 - val_recall: 0.9333 - 1s/epoch - 11ms/step\n",
            "Epoch 17/30\n",
            "112/112 - 1s - loss: 5.5524e-07 - fn: 6.0000 - fp: 5490.0000 - tn: 221939.0000 - tp: 411.0000 - precision: 0.0696 - recall: 0.9856 - val_loss: 0.0153 - val_fn: 8.0000 - val_fp: 305.0000 - val_tn: 56581.0000 - val_tp: 67.0000 - val_precision: 0.1801 - val_recall: 0.8933 - 1s/epoch - 11ms/step\n",
            "Epoch 18/30\n",
            "112/112 - 1s - loss: 4.2361e-07 - fn: 6.0000 - fp: 4513.0000 - tn: 222916.0000 - tp: 411.0000 - precision: 0.0835 - recall: 0.9856 - val_loss: 0.0265 - val_fn: 8.0000 - val_fp: 587.0000 - val_tn: 56299.0000 - val_tp: 67.0000 - val_precision: 0.1024 - val_recall: 0.8933 - 1s/epoch - 11ms/step\n",
            "Epoch 19/30\n",
            "112/112 - 1s - loss: 3.2209e-07 - fn: 3.0000 - fp: 3232.0000 - tn: 224197.0000 - tp: 414.0000 - precision: 0.1135 - recall: 0.9928 - val_loss: 0.0209 - val_fn: 8.0000 - val_fp: 456.0000 - val_tn: 56430.0000 - val_tp: 67.0000 - val_precision: 0.1281 - val_recall: 0.8933 - 1s/epoch - 11ms/step\n",
            "Epoch 20/30\n",
            "112/112 - 1s - loss: 2.3674e-07 - fn: 1.0000 - fp: 2932.0000 - tn: 224497.0000 - tp: 416.0000 - precision: 0.1243 - recall: 0.9976 - val_loss: 0.0145 - val_fn: 10.0000 - val_fp: 265.0000 - val_tn: 56621.0000 - val_tp: 65.0000 - val_precision: 0.1970 - val_recall: 0.8667 - 1s/epoch - 12ms/step\n",
            "Epoch 21/30\n",
            "112/112 - 1s - loss: 2.2848e-07 - fn: 2.0000 - fp: 2597.0000 - tn: 224832.0000 - tp: 415.0000 - precision: 0.1378 - recall: 0.9952 - val_loss: 0.0159 - val_fn: 8.0000 - val_fp: 300.0000 - val_tn: 56586.0000 - val_tp: 67.0000 - val_precision: 0.1826 - val_recall: 0.8933 - 1s/epoch - 12ms/step\n",
            "Epoch 22/30\n",
            "112/112 - 1s - loss: 2.6219e-07 - fn: 5.0000 - fp: 2644.0000 - tn: 224785.0000 - tp: 412.0000 - precision: 0.1348 - recall: 0.9880 - val_loss: 0.0336 - val_fn: 7.0000 - val_fp: 645.0000 - val_tn: 56241.0000 - val_tp: 68.0000 - val_precision: 0.0954 - val_recall: 0.9067 - 1s/epoch - 11ms/step\n",
            "Epoch 23/30\n",
            "112/112 - 1s - loss: 4.1903e-07 - fn: 5.0000 - fp: 3671.0000 - tn: 223758.0000 - tp: 412.0000 - precision: 0.1009 - recall: 0.9880 - val_loss: 0.1883 - val_fn: 6.0000 - val_fp: 2070.0000 - val_tn: 54816.0000 - val_tp: 69.0000 - val_precision: 0.0323 - val_recall: 0.9200 - 1s/epoch - 11ms/step\n",
            "Epoch 24/30\n",
            "112/112 - 1s - loss: 5.6937e-07 - fn: 7.0000 - fp: 6129.0000 - tn: 221300.0000 - tp: 410.0000 - precision: 0.0627 - recall: 0.9832 - val_loss: 0.0412 - val_fn: 8.0000 - val_fp: 797.0000 - val_tn: 56089.0000 - val_tp: 67.0000 - val_precision: 0.0775 - val_recall: 0.8933 - 1s/epoch - 11ms/step\n",
            "Epoch 25/30\n",
            "112/112 - 1s - loss: 6.7104e-07 - fn: 6.0000 - fp: 5301.0000 - tn: 222128.0000 - tp: 411.0000 - precision: 0.0720 - recall: 0.9856 - val_loss: 0.0325 - val_fn: 11.0000 - val_fp: 572.0000 - val_tn: 56314.0000 - val_tp: 64.0000 - val_precision: 0.1006 - val_recall: 0.8533 - 1s/epoch - 11ms/step\n",
            "Epoch 26/30\n",
            "112/112 - 1s - loss: 4.0846e-07 - fn: 4.0000 - fp: 4325.0000 - tn: 223104.0000 - tp: 413.0000 - precision: 0.0872 - recall: 0.9904 - val_loss: 0.0166 - val_fn: 10.0000 - val_fp: 344.0000 - val_tn: 56542.0000 - val_tp: 65.0000 - val_precision: 0.1589 - val_recall: 0.8667 - 1s/epoch - 11ms/step\n",
            "Epoch 27/30\n",
            "112/112 - 1s - loss: 2.4929e-07 - fn: 3.0000 - fp: 2427.0000 - tn: 225002.0000 - tp: 414.0000 - precision: 0.1457 - recall: 0.9928 - val_loss: 0.0165 - val_fn: 9.0000 - val_fp: 334.0000 - val_tn: 56552.0000 - val_tp: 66.0000 - val_precision: 0.1650 - val_recall: 0.8800 - 1s/epoch - 11ms/step\n",
            "Epoch 28/30\n",
            "112/112 - 1s - loss: 3.0529e-07 - fn: 2.0000 - fp: 2686.0000 - tn: 224743.0000 - tp: 415.0000 - precision: 0.1338 - recall: 0.9952 - val_loss: 0.0387 - val_fn: 9.0000 - val_fp: 367.0000 - val_tn: 56519.0000 - val_tp: 66.0000 - val_precision: 0.1524 - val_recall: 0.8800 - 1s/epoch - 11ms/step\n",
            "Epoch 29/30\n",
            "112/112 - 1s - loss: 2.1522e-06 - fn: 9.0000 - fp: 6385.0000 - tn: 221044.0000 - tp: 408.0000 - precision: 0.0601 - recall: 0.9784 - val_loss: 0.0195 - val_fn: 11.0000 - val_fp: 243.0000 - val_tn: 56643.0000 - val_tp: 64.0000 - val_precision: 0.2085 - val_recall: 0.8533 - 1s/epoch - 11ms/step\n",
            "Epoch 30/30\n",
            "112/112 - 1s - loss: 4.8952e-07 - fn: 7.0000 - fp: 3796.0000 - tn: 223633.0000 - tp: 410.0000 - precision: 0.0975 - recall: 0.9832 - val_loss: 0.1350 - val_fn: 6.0000 - val_fp: 2257.0000 - val_tn: 54629.0000 - val_tp: 69.0000 - val_precision: 0.0297 - val_recall: 0.9200 - 1s/epoch - 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8310aeb0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L7iFgWtJeI_"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "At the end of training, out of 56,961 validation transactions, we are:\n",
        "\n",
        "- Correctly identifying 66 of them as fraudulent\n",
        "- Missing 9 fraudulent transactions\n",
        "- At the cost of incorrectly flagging 441 legitimate transactions\n",
        "\n",
        "In the real world, one would put an even higher weight on class 1,\n",
        "so as to reflect that False Negatives are more costly than False Positives.\n",
        "\n",
        "Next time your credit card gets  declined in an online purchase -- this is why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgiKBcwwTrvk"
      },
      "source": [
        "## Try to tune any set of hyperparameters in the problem above with optuna library. Possible variants\n",
        "\n",
        "* weights of the classes\n",
        "* number of layers in the neural network\n",
        "* learning rate and batch size\n",
        "\n",
        "Also you are able to choose any metric you want."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE IS HERE"
      ],
      "metadata": {
        "id": "E1au_QC0RkzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSPaPDQkaTk0"
      },
      "source": [
        "# Materials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykAl6yqoaWJb"
      },
      "source": [
        "* [ZOOpt](https://github.com/eyounx/ZOOpt) A python package of Zeroth-Order Optimization\n",
        "* [Nevergrad](https://github.com/facebookresearch/nevergrad) A Python toolbox for performing gradient-free optimization\n",
        "* [Optuna](https://colab.research.google.com/github/optuna/optuna-examples/blob/main/quickstart.ipynb) tutorial."
      ]
    }
  ]
}