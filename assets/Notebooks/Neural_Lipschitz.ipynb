{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lipschitz constant of a convolutional layer in neural network\n",
    "\n",
    "It was observed, that small perturbation in Neural Network input could lead to significant errors, i.e. misclassifications.\n",
    "\n",
    "![https://escholarship.org/content/qt3k2780bg/qt3k2780bg_noSplash_e0803cb722032c480ec3468d84e60e2a.pdf?t=qqf3iz](https://fmin.xyz/docs/applications/adv_attack.png)\n",
    "\n",
    "Lipschitz constant bounds the magnitude of the output of a function, so it cannot change drastically with a slight change in the input\n",
    "\n",
    "$$\n",
    "\\|NN(image) - NN(image+\\varepsilon)\\| \\leq L\\|\\varepsilon\\|\n",
    "$$\n",
    "\n",
    "In this notebook we will try to estimate Lipschitz constant of some convolutional layer of a Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power method for the singular value estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/bratishka/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "def fix_seed(seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "\n",
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def power_method_for_nn_layer(layer, n_iterations=10):\n",
    "    sigmas = []\n",
    "    # print(f\"Layer norm {torch.norm(list(layer.parameters())[0])}\")\n",
    "    x = copy.deepcopy(input_batch)*1.0\n",
    "    # print(torch.norm(x))\n",
    "    # Create custom layer from pretrained layer:\n",
    "    conv_layer = torch.nn.Conv2d(3, 64, 7, padding=3)\n",
    "    conv_t_layer = torch.nn.ConvTranspose2d(64, 3, 7, padding=3)\n",
    "\n",
    "    conv_layer.weight.data = copy.deepcopy(list(layer.parameters())[0].data)\n",
    "    conv_layer.bias.data.zero_()\n",
    "\n",
    "    conv_t_layer.weight.data = copy.deepcopy(list(layer.parameters())[0].data)\n",
    "    conv_t_layer.bias.data.zero_()\n",
    "\n",
    "    # print(f\"W norm {torch.norm(list(conv_layer.parameters())[0])}\")\n",
    "    # print(f\"WT norm {torch.norm(list(conv_t_layer.parameters())[0])}\")\n",
    "    # print(f\"x norm {torch.norm(x)}\")\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        # y =   W@x computation\n",
    "        # print(f\"âœ… {list(conv_layer.parameters())[0][0][0][0][0]}\")\n",
    "\n",
    "        y = conv_layer(x)\n",
    "        # print(f\"y norm {torch.norm(y)}\")\n",
    "\n",
    "        # x = W.T@y computation\n",
    "        x = conv_t_layer(y)\n",
    "        x_norm = torch.norm(x)\n",
    "\n",
    "        # Normalization\n",
    "        x = x/x_norm\n",
    "       \n",
    "        # sigma computation\n",
    "        sigma = torch.norm(conv_layer(x))/torch.norm(x)\n",
    "        sigmas.append(sigma)\n",
    "    \n",
    "    return sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f90b0919a90>]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "sigmas = power_method_for_nn_layer(model.conv1, 500)\n",
    "plt.semilogy([sigmas[-1] - sigma for sigma in sigmas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(15.8986),\n",
       " tensor(15.8986),\n",
       " tensor(15.8986),\n",
       " tensor(15.8986),\n",
       " tensor(15.8986),\n",
       " tensor(15.8986),\n",
       " tensor(15.8987),\n",
       " tensor(15.8987),\n",
       " tensor(15.8987),\n",
       " tensor(15.8987)]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmas[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def power_method_for_nn_tensor(tensor, n_iterations=10):\n",
    "    # fix_seed()\n",
    "    print(f\"Layer norm {torch.norm(tensor)}\")\n",
    "    x = copy.deepcopy(input_batch)*1.0\n",
    "    # print(torch.norm(x))\n",
    "    # Create custom layer from pretrained layer:\n",
    "    conv_layer = torch.nn.Conv2d(3, 64, 7, padding=3)\n",
    "    conv_t_layer = torch.nn.ConvTranspose2d(64, 3, 7, padding=3)\n",
    "\n",
    "    # Initialization done right:\n",
    "    for p_new, p_new_t in zip(conv_layer.parameters(),\n",
    "                                conv_t_layer.parameters()):\n",
    "        p_c = copy.deepcopy(tensor)\n",
    "        print(p_new.shape)\n",
    "        p_new.data.copy_(p_c)\n",
    "        p_c_t = copy.deepcopy(tensor)\n",
    "        p_new_t.data.copy_(p_c_t)\n",
    "\n",
    "    print(f\"W norm {torch.norm(list(conv_layer.parameters())[0])}\")\n",
    "    print(f\"WT norm {torch.norm(list(conv_t_layer.parameters())[0])}\")\n",
    "    print(f\"x norm {torch.norm(x)}\")\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        # y =   W@x computation\n",
    "        print(f\"âœ… {list(conv_layer.parameters())[0][0][0][0][0]}\")\n",
    "\n",
    "        y = conv_layer(x)\n",
    "        print(f\"y norm {torch.norm(y)}\")\n",
    "        y_norm = torch.norm(y)\n",
    "\n",
    "        # x = W.T@y computation\n",
    "        x = conv_t_layer(y)\n",
    "        x_norm = torch.norm(x)\n",
    "\n",
    "        # Normalization\n",
    "        x = x/x_norm\n",
    "       \n",
    "        # sigma computation\n",
    "        sigma = torch.norm(conv_layer(x))/torch.norm(x)\n",
    "        print(sigma)\n",
    "    \n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "Layer norm 12.57936954498291\n",
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (7) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9y/4tbcgl7s7l7gkqrd_n34n6fr0000gn/T/ipykernel_5680/3254048544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_method_for_nn_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9y/4tbcgl7s7l7gkqrd_n34n6fr0000gn/T/ipykernel_5680/961907821.py\u001b[0m in \u001b[0;36mpower_method_for_nn_tensor\u001b[0;34m(tensor, n_iterations)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mp_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mp_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mp_c_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mp_new_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_c_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (7) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "tensor = list(model.conv1.parameters())[0]\n",
    "print(tensor.shape)\n",
    "sigma = power_method_for_nn_tensor(tensor, n_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦„ Parameter containing:\n",
      "tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,\n",
      "            1.7083e-02, -1.2694e-02],\n",
      "          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,\n",
      "           -1.2907e-01,  3.7424e-03],\n",
      "          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,\n",
      "            2.5632e-01,  6.3573e-02],\n",
      "          ...,\n",
      "          [-2.7535e-02,  1.6045e-02,  7.2595e-02,  ..., -3.3285e-01,\n",
      "           -4.2058e-01, -2.5781e-01],\n",
      "          [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  ...,  4.1384e-01,\n",
      "            3.9359e-01,  1.6606e-01],\n",
      "          [-1.3736e-02, -3.6746e-03, -2.4084e-02,  ..., -1.5070e-01,\n",
      "           -8.2230e-02, -5.7828e-03]],\n",
      "\n",
      "         [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  ...,  3.2521e-02,\n",
      "            6.6221e-04, -2.5743e-02],\n",
      "          [ 4.5687e-02,  3.3603e-02, -1.0453e-01,  ..., -3.1253e-01,\n",
      "           -1.6051e-01, -1.2826e-03],\n",
      "          [-8.3730e-04,  9.8420e-02,  4.0210e-01,  ...,  7.0789e-01,\n",
      "            3.6887e-01,  1.2455e-01],\n",
      "          ...,\n",
      "          [-5.5926e-02, -5.2239e-03,  2.7081e-02,  ..., -4.6178e-01,\n",
      "           -5.7080e-01, -3.6552e-01],\n",
      "          [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  ...,  5.4636e-01,\n",
      "            4.8276e-01,  1.9867e-01],\n",
      "          [ 5.3051e-03,  6.6938e-03, -1.7254e-02,  ..., -1.4822e-01,\n",
      "           -7.7248e-02,  7.2183e-04]],\n",
      "\n",
      "         [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  ...,  8.9177e-02,\n",
      "            3.3655e-02, -2.0102e-02],\n",
      "          [ 1.5398e-02, -1.8648e-02, -1.2591e-01,  ..., -2.5342e-01,\n",
      "           -1.2980e-01, -2.7975e-02],\n",
      "          [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  ...,  3.4872e-01,\n",
      "            1.0433e-01,  1.8413e-02],\n",
      "          ...,\n",
      "          [-2.8356e-02,  1.8404e-02,  9.8647e-02,  ..., -1.1740e-01,\n",
      "           -2.5760e-01, -1.5451e-01],\n",
      "          [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  ...,  2.4141e-01,\n",
      "            2.4345e-01,  1.1796e-01],\n",
      "          [ 7.4684e-04,  7.7677e-04, -1.0050e-02,  ..., -1.4865e-01,\n",
      "           -1.1754e-01, -3.8350e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4154e-03, -4.0645e-03,  3.1589e-03,  ..., -3.7026e-02,\n",
      "           -2.5158e-02, -4.7945e-02],\n",
      "          [ 5.1310e-02,  5.3402e-02,  8.0436e-02,  ...,  1.4480e-01,\n",
      "            1.4287e-01,  1.2312e-01],\n",
      "          [-7.3337e-03,  2.1755e-03,  3.7580e-02,  ...,  6.1517e-02,\n",
      "            8.0324e-02,  1.1715e-01],\n",
      "          ...,\n",
      "          [-2.6754e-02, -1.2297e-01, -1.3653e-01,  ..., -1.4068e-01,\n",
      "           -1.1155e-01, -4.9556e-02],\n",
      "          [ 2.3524e-02, -1.7288e-02, -1.1122e-02,  ..., -1.8826e-02,\n",
      "           -2.3320e-02, -2.9474e-02],\n",
      "          [ 2.8689e-02,  2.1659e-02,  4.7888e-02,  ...,  2.5498e-02,\n",
      "            3.5346e-02,  1.1280e-02]],\n",
      "\n",
      "         [[ 4.6919e-04,  1.2153e-02,  4.2035e-02,  ...,  4.6403e-02,\n",
      "            4.0423e-02, -1.4439e-02],\n",
      "          [ 4.3463e-02,  6.8779e-02,  1.3268e-01,  ...,  2.8606e-01,\n",
      "            2.6905e-01,  2.0935e-01],\n",
      "          [-5.7621e-02, -2.2642e-02,  3.0547e-02,  ...,  1.3763e-01,\n",
      "            1.6538e-01,  1.7946e-01],\n",
      "          ...,\n",
      "          [-1.0816e-01, -2.5227e-01, -2.9742e-01,  ..., -2.8503e-01,\n",
      "           -2.1493e-01, -1.0320e-01],\n",
      "          [ 4.0709e-02, -3.2771e-02, -6.3450e-02,  ..., -9.2360e-02,\n",
      "           -6.9876e-02, -4.9841e-02],\n",
      "          [ 8.2942e-02,  8.7580e-02,  1.0111e-01,  ...,  5.2714e-02,\n",
      "            6.0968e-02,  4.1198e-02]],\n",
      "\n",
      "         [[-1.6391e-02, -1.3870e-02,  5.2810e-03,  ...,  4.3698e-02,\n",
      "            2.2707e-02, -4.5983e-02],\n",
      "          [ 3.3202e-02,  4.2014e-02,  9.3500e-02,  ...,  2.6162e-01,\n",
      "            2.2970e-01,  1.6694e-01],\n",
      "          [-4.5987e-02, -1.6365e-02,  2.6811e-02,  ...,  1.4951e-01,\n",
      "            1.3216e-01,  1.3579e-01],\n",
      "          ...,\n",
      "          [-7.2129e-02, -1.8902e-01, -2.3389e-01,  ..., -1.9038e-01,\n",
      "           -1.5609e-01, -7.5974e-02],\n",
      "          [ 5.1161e-02, -2.5815e-02, -6.9357e-02,  ..., -5.8999e-02,\n",
      "           -6.1550e-02, -4.4555e-02],\n",
      "          [ 1.1174e-01,  7.8979e-02,  6.5849e-02,  ...,  3.1617e-02,\n",
      "            2.5221e-02,  7.4257e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
      "           -1.0905e-07, -8.3421e-08],\n",
      "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
      "           -4.3836e-08, -3.0538e-09],\n",
      "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
      "           -1.0951e-09,  4.2442e-08],\n",
      "          ...,\n",
      "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
      "           -4.7666e-08, -1.3265e-08],\n",
      "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
      "            1.0628e-07,  9.3316e-08],\n",
      "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
      "            1.7710e-07,  1.7166e-07]],\n",
      "\n",
      "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
      "           -1.3309e-07, -1.0820e-07],\n",
      "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
      "           -6.7022e-08, -2.2574e-08],\n",
      "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
      "           -7.9591e-09,  3.9750e-08],\n",
      "          ...,\n",
      "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
      "           -5.9930e-08, -1.8247e-08],\n",
      "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
      "            4.1781e-08,  4.5901e-08],\n",
      "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
      "            8.7550e-08,  9.8837e-08]],\n",
      "\n",
      "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
      "           -2.6217e-08, -1.5649e-08],\n",
      "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
      "            7.1450e-08,  9.7615e-08],\n",
      "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
      "            1.3487e-07,  1.6449e-07],\n",
      "          ...,\n",
      "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
      "            6.8382e-08,  1.1367e-07],\n",
      "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
      "            1.1723e-07,  1.4394e-07],\n",
      "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
      "            1.3333e-07,  1.5844e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.1896e-02, -3.0206e-02,  1.9225e-02,  ...,  4.3665e-02,\n",
      "           -2.2114e-02, -4.2214e-02],\n",
      "          [-3.8061e-02,  6.0774e-03,  4.5797e-02,  ...,  9.6029e-02,\n",
      "            5.9254e-02,  2.9958e-02],\n",
      "          [-2.9672e-02,  2.7766e-03,  2.0457e-02,  ...,  5.9828e-02,\n",
      "            4.1422e-02,  2.3134e-02],\n",
      "          ...,\n",
      "          [ 1.1916e-02,  4.5701e-02,  4.4892e-02,  ...,  4.7419e-02,\n",
      "            2.2274e-02, -5.4993e-03],\n",
      "          [-3.2468e-02, -1.2210e-02,  2.2023e-02,  ...,  5.8061e-02,\n",
      "           -7.5033e-03, -5.9736e-02],\n",
      "          [-4.3314e-02, -2.8162e-02, -5.9126e-03,  ...,  8.8460e-02,\n",
      "            8.4406e-03, -5.0019e-02]],\n",
      "\n",
      "         [[-6.1292e-02, -1.4004e-02,  1.7229e-02,  ...,  1.8349e-02,\n",
      "           -3.2708e-02, -4.1060e-02],\n",
      "          [-3.1506e-02,  2.4460e-02,  4.5516e-02,  ...,  6.6806e-02,\n",
      "            4.6687e-02,  3.3248e-02],\n",
      "          [-3.2216e-02,  2.0718e-02,  2.3343e-02,  ...,  3.5265e-02,\n",
      "            3.6478e-02,  3.1291e-02],\n",
      "          ...,\n",
      "          [ 1.7739e-02,  6.1040e-02,  4.8247e-02,  ...,  3.7785e-02,\n",
      "            2.8894e-02,  1.3984e-02],\n",
      "          [-1.0890e-02,  2.2079e-02,  4.2737e-02,  ...,  6.0247e-02,\n",
      "            1.6197e-02, -1.2493e-02],\n",
      "          [-2.2284e-02,  1.3220e-02,  3.0897e-02,  ...,  1.0403e-01,\n",
      "            4.0119e-02, -5.3310e-03]],\n",
      "\n",
      "         [[-8.5322e-02, -4.2603e-02,  6.8145e-03,  ...,  3.0751e-02,\n",
      "           -3.4818e-02, -4.9945e-02],\n",
      "          [-2.9215e-02,  1.8165e-02,  5.1092e-02,  ...,  9.0200e-02,\n",
      "            5.3438e-02,  4.0169e-02],\n",
      "          [-3.9932e-02, -1.1100e-03,  9.6176e-03,  ...,  2.4114e-02,\n",
      "            2.6298e-02,  2.5489e-02],\n",
      "          ...,\n",
      "          [-3.1890e-03,  3.0454e-02,  1.6316e-02,  ...,  5.5054e-03,\n",
      "           -6.2689e-03, -8.4638e-03],\n",
      "          [-2.2995e-02, -2.8211e-03,  2.3203e-02,  ...,  3.5888e-02,\n",
      "           -1.4296e-02, -3.2419e-02],\n",
      "          [-9.8894e-03,  7.0542e-03,  1.0659e-02,  ...,  7.0495e-02,\n",
      "            1.2996e-02, -8.3417e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.8699e-03,  1.9911e-02,  3.4208e-02,  ...,  2.8694e-02,\n",
      "            1.2820e-02,  1.8142e-02],\n",
      "          [ 8.7942e-03, -3.2875e-02, -3.5713e-02,  ...,  7.2533e-02,\n",
      "            4.5889e-02,  5.2383e-02],\n",
      "          [-3.6122e-02, -1.1878e-01, -1.3767e-01,  ...,  3.3811e-02,\n",
      "            3.7806e-02,  2.6944e-02],\n",
      "          ...,\n",
      "          [ 1.7322e-02,  3.9589e-03, -8.2269e-03,  ...,  2.7543e-03,\n",
      "            1.8313e-02,  1.6057e-02],\n",
      "          [-9.5007e-04,  1.6428e-02,  1.7156e-02,  ...,  3.3672e-03,\n",
      "            2.2857e-02,  6.5783e-04],\n",
      "          [ 6.1727e-03,  2.7145e-02,  1.4340e-02,  ...,  7.5867e-03,\n",
      "            1.8770e-02,  1.5624e-02]],\n",
      "\n",
      "         [[-1.3423e-02, -5.0696e-04,  8.0959e-03,  ..., -6.0963e-03,\n",
      "            9.2341e-03,  1.5751e-02],\n",
      "          [-1.8343e-02, -6.7982e-02, -7.0685e-02,  ...,  2.9855e-02,\n",
      "            2.6264e-02,  2.3773e-02],\n",
      "          [-5.4359e-02, -1.4663e-01, -1.6211e-01,  ...,  1.1781e-02,\n",
      "            3.2477e-02,  1.1980e-02],\n",
      "          ...,\n",
      "          [ 8.3686e-04, -1.7564e-02, -1.9535e-02,  ..., -4.1382e-03,\n",
      "            2.4658e-02,  1.2893e-02],\n",
      "          [-6.3183e-04,  1.1788e-02,  2.4810e-02,  ...,  6.1105e-03,\n",
      "            3.9210e-02,  9.6696e-03],\n",
      "          [-7.1831e-03,  6.6918e-03,  5.2723e-03,  ..., -7.6077e-03,\n",
      "            2.7253e-02,  1.7735e-02]],\n",
      "\n",
      "         [[-2.3753e-04, -4.9343e-03,  2.2991e-03,  ..., -4.7958e-02,\n",
      "           -2.6154e-02, -2.3525e-02],\n",
      "          [-3.3053e-04, -5.1502e-02, -5.9977e-02,  ..., -1.7369e-02,\n",
      "           -2.3337e-02, -3.7312e-02],\n",
      "          [-2.2674e-02, -9.9412e-02, -1.1176e-01,  ..., -1.1725e-02,\n",
      "           -8.3744e-03, -4.0615e-02],\n",
      "          ...,\n",
      "          [ 1.1437e-02, -8.0313e-03, -1.4955e-03,  ..., -3.4133e-02,\n",
      "           -8.7267e-03, -2.3526e-02],\n",
      "          [ 2.9522e-03,  6.7770e-04,  1.9933e-02,  ..., -2.2002e-02,\n",
      "            1.4814e-02, -1.4487e-02],\n",
      "          [-1.9085e-02, -2.9430e-02, -2.3284e-02,  ..., -4.8587e-02,\n",
      "           -1.3049e-02, -2.4368e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6296e-02,  7.1996e-03,  1.9100e-02,  ...,  1.9602e-02,\n",
      "            1.4870e-02, -1.7298e-02],\n",
      "          [-1.1061e-02,  8.5665e-02,  1.2667e-01,  ...,  1.3744e-02,\n",
      "           -5.5036e-05, -3.0162e-02],\n",
      "          [ 1.1322e-01,  1.8634e-01,  5.0658e-02,  ..., -1.7333e-01,\n",
      "           -7.2041e-02, -6.2474e-02],\n",
      "          ...,\n",
      "          [-5.3062e-02, -2.5781e-01, -2.6747e-01,  ...,  2.6781e-01,\n",
      "            1.4344e-01,  5.5145e-02],\n",
      "          [-2.1009e-02, -2.9969e-02,  1.0245e-01,  ...,  2.0843e-01,\n",
      "           -4.1518e-03, -3.8118e-02],\n",
      "          [-2.2155e-02,  1.2380e-02,  8.4302e-02,  ..., -4.4992e-02,\n",
      "           -1.4687e-01, -9.0890e-02]],\n",
      "\n",
      "         [[-5.3969e-03,  3.2799e-02,  1.5486e-02,  ..., -7.7451e-03,\n",
      "            3.0229e-03,  1.1216e-03],\n",
      "          [ 6.1723e-02,  1.4899e-01,  1.4645e-01,  ..., -2.8897e-02,\n",
      "           -2.0227e-02, -9.1878e-03],\n",
      "          [ 1.6146e-01,  2.0886e-01, -2.5589e-02,  ..., -2.7278e-01,\n",
      "           -1.0735e-01, -6.2971e-02],\n",
      "          ...,\n",
      "          [-1.3723e-01, -4.0863e-01, -3.8551e-01,  ...,  4.0846e-01,\n",
      "            2.6202e-01,  1.3491e-01],\n",
      "          [-5.9388e-02, -6.1187e-02,  1.4197e-01,  ...,  3.5780e-01,\n",
      "            9.0893e-02, -1.7392e-03],\n",
      "          [ 7.8613e-03,  5.8403e-02,  1.5339e-01,  ...,  4.7045e-02,\n",
      "           -1.0095e-01, -9.7920e-02]],\n",
      "\n",
      "         [[-5.6799e-03,  1.3425e-02, -2.6461e-02,  ...,  4.4881e-03,\n",
      "            2.0666e-03,  1.3902e-02],\n",
      "          [ 6.5943e-03,  4.5181e-02,  6.0260e-02,  ...,  1.4368e-02,\n",
      "           -5.0725e-03,  4.0505e-03],\n",
      "          [ 5.5257e-02,  1.2397e-01,  4.3193e-02,  ..., -1.4486e-01,\n",
      "           -7.4489e-02, -5.7533e-02],\n",
      "          ...,\n",
      "          [-3.1513e-02, -1.6334e-01, -1.5795e-01,  ...,  2.2904e-01,\n",
      "            1.2017e-01,  7.1998e-02],\n",
      "          [-1.0456e-02, -1.1248e-03,  8.4582e-02,  ...,  1.5748e-01,\n",
      "            2.2142e-02, -1.0083e-02],\n",
      "          [-4.8639e-03, -5.0065e-03,  3.6341e-02,  ..., -2.4361e-02,\n",
      "           -7.1195e-02, -6.6788e-02]]]], requires_grad=True)\n",
      "ðŸ¦„ Parameter containing:\n",
      "tensor([ 0.0569, -0.0383,  0.0096, -0.0277, -0.0704, -0.0400, -0.0056,  0.0233,\n",
      "        -0.0645,  0.0498,  0.0045, -0.0519,  0.0643, -0.0264,  0.0220, -0.0548,\n",
      "         0.0792, -0.0393,  0.0691, -0.0208,  0.0322, -0.0426,  0.0273,  0.0544,\n",
      "         0.0069,  0.0253, -0.0694,  0.0164, -0.0465,  0.0817,  0.0278, -0.0382,\n",
      "         0.0020, -0.0561, -0.0773,  0.0416, -0.0276, -0.0596,  0.0822,  0.0026,\n",
      "         0.0482, -0.0810,  0.0761,  0.0237, -0.0603,  0.0619, -0.0227,  0.0669,\n",
      "         0.0615,  0.0195,  0.0521, -0.0700, -0.0277, -0.0308,  0.0159, -0.0266,\n",
      "         0.0103,  0.0593,  0.0735,  0.0176,  0.0342,  0.0058,  0.0424, -0.0750],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for par in conv1_custom.parameters():\n",
    "    print(f\"ðŸ¦„ {par}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier will help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = torch.permute(model.conv1.weight.data, [2, 3, 0, 1])\n",
    "input_shape = input_batch.shape\n",
    "s = np.fft.fft2(kernel, (224, 224), axes=[0, 1])\n",
    "s = np.linalg.svd(s, compute_uv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.916427973378767"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64, 3, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "conv_layer = torch.nn.Conv2d(3, 64, 7, padding=3)\n",
    "conv_t_layer = torch.nn.ConvTranspose2d(64, 3, 7, padding=3)\n",
    "\n",
    "print(conv_layer.weight.shape)\n",
    "print(conv_t_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1013.8447, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "# With square kernels and equal stride\n",
    "fix_seed()\n",
    "m = nn.Conv2d(16, 33, 3)\n",
    "# input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n",
    "print(torch.norm(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2804, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 112, 112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 112, 112])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_output = model.conv1(input_batch)\n",
    "print(conv1_output.shape)\n",
    "conv_t_layer = torch.nn.ConvTranspose2d(64, 3, 7, padding=3)\n",
    "conv_t_layer(conv1_output).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 112, 112])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_custom = torch.nn.Conv2d(3, 64, 7, stride=2, padding=3)\n",
    "conv1_custom_output = conv1_custom(input_batch)\n",
    "conv1_custom_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.conv1.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_custom = torch.nn.Conv2d(3, 64, 7, stride=2, padding=3)\n",
    "list(conv1_custom.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_t_layer = torch.nn.ConvTranspose2d(64, 3, 7, padding=3)\n",
    "list(conv_t_layer.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_t_layer = torch.nn.ConvTranspose2d(64, 3, 7, padding=3)\n",
    "conv_t_layer(conv1_output).shape\n",
    "for p_new, p_new_t, p in zip(conv1_custom.parameters(),\n",
    "                                conv_t_layer.parameters(),\n",
    "                                model.conv1.parameters()):\n",
    "        p_new.data.copy_(p)\n",
    "        p_new_t.data.copy_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new_t.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.5794, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(list(model.conv1.parameters())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.5794, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(list(conv1_custom.parameters())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 12, 12])\n",
      "torch.Size([1, 16, 6, 6])\n",
      "torch.Size([1, 16, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# With square kernels and equal stride\n",
    "m = nn.ConvTranspose2d(16, 33, 3, stride=2)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n",
    "# exact output size can be also specified as an argument\n",
    "input = torch.randn(1, 16, 12, 12)\n",
    "print(input.size())\n",
    "downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1)\n",
    "upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1)\n",
    "h = downsample(input)\n",
    "print(h.size())\n",
    "output = upsample(h, output_size=input.size())\n",
    "print(output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2db2dbd783029c302ae1bc6d916ea5f6a36bfcb987e05379133dc550ca9c62ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
